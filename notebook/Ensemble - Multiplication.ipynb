{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd30aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AlbertForQuestionAnswering, AlbertTokenizerFast, XLNetForQuestionAnswering, XLNetTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a37d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_dict = torch.load('../model/xlnet.pt',map_location=torch.device(\"cpu\"))\n",
    "albert_dict = torch.load('../model/albert.pt',map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de7f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForQuestionAnswering were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['answer_class.dense_0.bias', 'end_logits.LayerNorm.weight', 'answer_class.dense_0.weight', 'end_logits.LayerNorm.bias', 'end_logits.dense_0.bias', 'end_logits.dense_1.bias', 'end_logits.dense_1.weight', 'start_logits.dense.weight', 'answer_class.dense_1.weight', 'start_logits.dense.bias', 'end_logits.dense_0.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17288dcfa19488a8303e465176a01db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wyiti\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wyiti\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating models\n",
    "\n",
    "# xlnet\n",
    "xlnet = XLNetForQuestionAnswering.from_pretrained('xlnet-base-cased')\n",
    "xlnet.load_state_dict(xlnet_dict[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "# albert\n",
    "albert = AlbertForQuestionAnswering.from_pretrained(\"albert-base-v2\")\n",
    "albert.load_state_dict(albert_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acbde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(Dataset):\n",
    "\n",
    "    def __init__(self, input_path, tokenizer_checkpoint):\n",
    "        \"\"\"\n",
    "        input_path: path that contains all the files - contexts, questions, answers, answer spans and question ids\n",
    "        \"\"\"\n",
    "        print(f\"Reading in Dataset from {input_path}\")\n",
    "        \n",
    "        with open(input_path + \"/context\", encoding='utf-8') as f:\n",
    "            contexts = f.read().split(\"\\t\")\n",
    "        with open(input_path + \"/question\", encoding='utf-8') as f:\n",
    "            questions = f.read().split(\"\\t\")\n",
    "        with open(input_path + \"/answer\", encoding='utf-8') as f:\n",
    "            answers = f.read().split(\"\\t\")\n",
    "        with open(input_path + \"/answer_span\", encoding='utf-8') as f:\n",
    "            spans = f.read().split(\"\\t\")\n",
    "        with open(input_path + \"/question_id\", encoding='utf-8') as f:\n",
    "            qids = f.read().split(\"\\t\")\n",
    "\n",
    "        self.contexts = [ctx.strip() for ctx in contexts][:100]\n",
    "        self.questions = [qn.strip() for qn in questions][:100]\n",
    "        self.answers = [ans.strip() for ans in answers][:100]\n",
    "        self.spans = [span.strip().split() for span in spans][:100]\n",
    "        self.start_indices = [int(x[0]) for x in self.spans]\n",
    "        self.end_indices = [int(x[1]) for x in self.spans]\n",
    "        self.qids = [qid.strip() for qid in qids][:100]\n",
    "\n",
    "        # intialise XLNetTokenizerFast for input tokenization\n",
    "        if tokenizer_checkpoint == \"xlnet-base-cased\":\n",
    "          self.tokenizer = XLNetTokenizerFast.from_pretrained(\"xlnet-base-cased\")\n",
    "        elif tokenizer_checkpoint == \"albert-base-v2\":\n",
    "          self.tokenizer = AlbertTokenizerFast.from_pretrained(\"albert-base-v2\")\n",
    "        self.tokenizer.padding_side = \"right\"\n",
    "\n",
    "        # extract tokenization outputs\n",
    "        self.tokenizer_dict = self.tokenize()\n",
    "        self.sample_mapping, self.offset_mapping = self.preprocess()\n",
    "\n",
    "        self.input_ids = self.tokenizer_dict[\"input_ids\"]\n",
    "        self.token_type_ids = self.tokenizer_dict[\"token_type_ids\"]\n",
    "        self.attention_mask = self.tokenizer_dict[\"attention_mask\"]\n",
    "\n",
    "\n",
    "    def tokenize(self, max_length=384, doc_stride=128):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        1. max_length: specifies the length of the tokenized text\n",
    "        2. doc_stride: defines the number of overlapping tokens\n",
    "\n",
    "        output:\n",
    "        1. tokenizer_dict, which contains\n",
    "        - input_ids: list of integer values representing the tokenized text; each integer corresponds to a specific token\n",
    "        - token_type_ids: to distinguish between question and context\n",
    "        - attention_mask: a binary mask that tells the model which tokens to mask/not mask\n",
    "        - sample_mapping: map from a feature to its corresponding example, since one question-context pair might give several features\n",
    "        - offset_mapping: maps each input id with the corresponding start and end characters in the original text\n",
    "\n",
    "        Tokenize examples (question-context pairs) with truncation and padding, but keep the overflows using a stride specified by `doc_stride`. \n",
    "        When the question-context input exceeds the `max_length`, it will contain more than one feature, and each of these features will have context\n",
    "        that overlaps a bit with the previous features, and the overlapping is determined by `doc_stride`. This is to ensure that although truncation\n",
    "        is performed, these overflows will ensure that no answer is missed as long as the answer span is shorter than the length of the overlap.\n",
    "        \"\"\"\n",
    "        print(\"Performing tokenization on dataset\")\n",
    "        tokenizer_dict = self.tokenizer(\n",
    "            self.questions,\n",
    "            self.contexts,\n",
    "            truncation=\"only_second\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "        return tokenizer_dict\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        This functions is to preprocess the outputs of the tokenizer dictionary.\n",
    "        Due to the possibility that an example has multiple features, this functions ensure that the start_positions and end_positions are mapped\n",
    "        correctly\n",
    "        \"\"\"\n",
    "        print(\"Preprocessing Dataset\")\n",
    "\n",
    "        sample_mapping = self.tokenizer_dict.pop(\"overflow_to_sample_mapping\")\n",
    "        offset_mapping = self.tokenizer_dict.pop(\"offset_mapping\")\n",
    "\n",
    "        self.tokenizer_dict[\"start_positions\"] = []\n",
    "        self.tokenizer_dict[\"end_positions\"] = []\n",
    "\n",
    "        for i, offsets in enumerate(offset_mapping):\n",
    "            input_ids = self.tokenizer_dict[\"input_ids\"][i]\n",
    "            cls_index = input_ids.index(self.tokenizer.cls_token_id)\n",
    "            sequence_ids = self.tokenizer_dict.sequence_ids(i)\n",
    "\n",
    "            sample_index = sample_mapping[i]\n",
    "            answer = self.answers[sample_index]\n",
    "            start_char = self.start_indices[sample_index]\n",
    "            end_char = self.end_indices[sample_index]\n",
    "\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # if answer is out of the span\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                self.tokenizer_dict[\"start_positions\"].append(cls_index)\n",
    "                self.tokenizer_dict[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                self.tokenizer_dict[\"start_positions\"].append(token_start_index - 1)\n",
    "\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                self.tokenizer_dict[\"end_positions\"].append(token_end_index + 1)\n",
    "        return sample_mapping, offset_mapping\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of features in the data\n",
    "        \"\"\"\n",
    "        return len(self.sample_mapping)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        og_index = self.sample_mapping[i]\n",
    "\n",
    "        item_dict = {\n",
    "            \"input_ids\": torch.tensor(self.input_ids[i]),\n",
    "            \"attention_mask\" : torch.tensor(self.attention_mask[i]),\n",
    "            \"start_positions\" : torch.tensor(self.tokenizer_dict[\"start_positions\"][i]),\n",
    "            \"end_positions\" : torch.tensor(self.tokenizer_dict[\"end_positions\"][i]),\n",
    "            \"og_indices\": og_index,\n",
    "            \"og_contexts\": self.contexts[og_index],\n",
    "            \"og_questions\": self.questions[og_index],\n",
    "            \"og_answers\": self.answers[og_index],\n",
    "            \"og_start_indices\": self.start_indices[og_index],\n",
    "            \"og_end_indices\": self.end_indices[og_index],\n",
    "            \"offset_mapping\": torch.tensor(self.offset_mapping[i]),\n",
    "            \"og_question_ids\": self.qids[og_index]\n",
    "\n",
    "        }\n",
    "        return item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5ff5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in Dataset from ../data/curated/test_data\n",
      "Performing tokenization on dataset\n",
      "Preprocessing Dataset\n",
      "Reading in Dataset from ../data/curated/test_data\n",
      "Performing tokenization on dataset\n",
      "Preprocessing Dataset\n"
     ]
    }
   ],
   "source": [
    "xlnet_data = SquadDataset(\"../data/curated/test_data\", \"xlnet-base-cased\")\n",
    "albert_data = SquadDataset(\"../data/curated/test_data\", \"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0d9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_albert(model, dataset, n_best_size=20, max_answer_length=30, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    test_dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    pred = {}\n",
    "\n",
    "    print(\"Making Predictions on Test Dataset\")\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            start = data[\"start_positions\"].to(device)\n",
    "            end = data[\"end_positions\"].to(device)\n",
    "\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            offset_mapping = data[\"offset_mapping\"]\n",
    "            context = data[\"og_contexts\"]\n",
    "            answer = data[\"og_answers\"]\n",
    "            question = data[\"og_questions\"]\n",
    "            qids = data[\"og_question_ids\"]\n",
    "\n",
    "            for i in range(len(input_ids)):\n",
    "\n",
    "                start_logits = F.softmax(output.start_logits[i], dim=0).cpu().detach().numpy()\n",
    "                end_logits = F.softmax(output.end_logits[i], dim=0).cpu().detach().numpy()\n",
    "                start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "\n",
    "                offsets = offset_mapping[i]\n",
    "                ctxt = context[i]\n",
    "                qid = qids[i]\n",
    "                ans = answer[i]\n",
    "\n",
    "                start_candidates = {}\n",
    "                end_candidates = {}\n",
    "\n",
    "                for start in start_indexes:\n",
    "                  logits = start_logits[start]\n",
    "                  start_char = offsets[start][0].item()\n",
    "                  if start_candidates.get(start_char) == None or start_candidates.get(start_char) < logits:\n",
    "                    start_candidates[start_char] = logits\n",
    "\n",
    "                for end in end_indexes:\n",
    "                  logits = end_logits[end]\n",
    "                  end_char = offsets[end][1].item()\n",
    "                  if end_candidates.get(end_char) == None or end_candidates.get(end_char) < logits:\n",
    "                    end_candidates[end_char] = logits\n",
    "\n",
    "                pred[(qid, ans, ctxt)] = {\"start\": start_candidates, \"end\": end_candidates}\n",
    "\n",
    "    return pred\n",
    "\n",
    "def test_xlnet(model, dataset, n_best_size=20, max_answer_length=30, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    test_dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    pred = {}\n",
    "\n",
    "    print(\"Making Predictions on Test Dataset\")\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            start = data[\"start_positions\"].to(device)\n",
    "            end = data[\"end_positions\"].to(device)\n",
    "\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            offset_mapping = data[\"offset_mapping\"]\n",
    "            context = data[\"og_contexts\"]\n",
    "            answer = data[\"og_answers\"]\n",
    "            question = data[\"og_questions\"]\n",
    "            qids = data[\"og_question_ids\"]\n",
    "\n",
    "            for i in range(len(input_ids)):\n",
    "                start_logits = output.start_top_log_probs[i].cpu().detach().numpy()\n",
    "                end_logits = output.end_top_log_probs[i].cpu().detach().numpy()\n",
    "                start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "\n",
    "                start_top_indexes = output.start_top_index[i]\n",
    "                end_top_indexes = output.end_top_index[i]\n",
    "\n",
    "                offsets = offset_mapping[i]\n",
    "                ctxt = context[i]\n",
    "                qid = qids[i]\n",
    "                ans = answer[i]\n",
    "\n",
    "                start_candidates = {}\n",
    "                end_candidates = {}\n",
    "                for start in start_indexes:\n",
    "                  logits = start_logits[start]\n",
    "                  start_index = start_top_indexes[start]\n",
    "                  start_char = offsets[start_index][0].item()\n",
    "                  if start_candidates.get(start_char) == None or start_candidates.get(start_char) < logits:\n",
    "                    start_candidates[start_char] = logits\n",
    "\n",
    "                for end in end_indexes:\n",
    "                  logits = end_logits[end]\n",
    "                  end_index = end_top_indexes[end]\n",
    "                  end_char = offsets[end_index][1].item()\n",
    "                  if end_candidates.get(end_char) == None or end_candidates.get(end_char) < logits:\n",
    "                    end_candidates[end_char] = logits\n",
    "\n",
    "                pred[(qid, ans, ctxt)] = {\"start\": start_candidates, \"end\": end_candidates}\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f88861",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_best_size = 20\n",
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2aba1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Predictions on Test Dataset\n",
      "Making Predictions on Test Dataset\n"
     ]
    }
   ],
   "source": [
    "albert_pred = test_albert(albert, albert_data, n_best_size, max_answer_length=30, device='cpu')\n",
    "xlnet_pred = test_xlnet(xlnet, xlnet_data, n_best_size, max_answer_length=30, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51be6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_pred.keys() == xlnet_pred.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69da3d",
   "metadata": {},
   "source": [
    "## Test on One Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2934bf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5729281baf94a219006aa122',\n",
       " 'Morocco and Ethiopia',\n",
       " \"Kenya is active in several sports, among them cricket, rallying, football, rugby union and boxing. The country is known chiefly for its dominance in middle-distance and long-distance athletics, having consistently produced Olympic and Commonwealth Games champions in various distance events, especially in 800 m, 1,500 m, 3,000 m steeplechase, 5,000 m, 10,000 m and the marathon. Kenyan athletes (particularly Kalenjin) continue to dominate the world of distance running, although competition from Morocco and Ethiopia has reduced this supremacy. Kenya's best-known athletes included the four-time women's Boston Marathon winner and two-time world champion Catherine Ndereba, 800m world record holder David Rudisha, former Marathon world record-holder Paul Tergat, and John Ngugi.\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_key = next(iter(albert_pred.keys()))\n",
    "example_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2574892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{498: 0.9720771, 481: 0.017689329, 223: 0.0024769614, 510: 0.0023586175, 493: 0.0015495653, 410: 0.0009279516, 380: 0.00050270767, 149: 0.00038564613, 472: 0.0002784642, 432: 0.00019917496, 506: 0.00012109086, 235: 0.00010860085, 454: 0.00010008272, 598: 8.6340566e-05, 397: 7.65662e-05, 169: 6.5610875e-05, 445: 5.91012e-05, 214: 5.425412e-05, 547: 4.9051225e-05, 523: 4.2499672e-05}\n",
      "{518: 0.9825853, 505: 0.0047336314, 545: 0.0024236734, 418: 0.0018414374, 546: 0.001636124, 247: 0.0009028191, 386: 0.0004802582, 470: 0.0004641103, 192: 0.00036206061, 509: 0.00031907737, 395: 0.00031776095, 522: 0.00028282977, 530: 0.00028102836, 263: 0.0002704699, 492: 0.00022276444, 552: 0.00019446915, 164: 0.00018576755, 378: 0.00016928012, 779: 0.00016635445, 603: 0.00013815687}\n"
     ]
    }
   ],
   "source": [
    "print(albert_pred[example_key][\"start\"])\n",
    "print(albert_pred[example_key][\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6027f63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{498: 0.9991967, 481: 0.00046435793, 510: 0.00020733097, 149: 5.7797803e-05, 493: 1.7289407e-05}\n",
      "{518: 0.9999844, 247: 0.36447152, 253: 0.13642289, 192: 0.11024575, 164: 0.107844435, 155: 0.1025703, 522: 0.00777565, 505: 0.0016211064, 509: 0.00014509284, 530: 0.00013444948, 470: 3.541387e-05}\n"
     ]
    }
   ],
   "source": [
    "print(xlnet_pred[example_key][\"start\"])\n",
    "print(xlnet_pred[example_key][\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b83f8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_start_keys = set(albert_pred[example_key][\"start\"]).intersection(xlnet_pred[example_key][\"start\"])\n",
    "common_end_keys = set(albert_pred[example_key][\"end\"]).intersection(xlnet_pred[example_key][\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abba6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{481, 493, 498, 149, 510}\n",
      "{192, 164, 518, 522, 530, 470, 247, 505, 509}\n"
     ]
    }
   ],
   "source": [
    "print(common_start_keys)\n",
    "print(common_end_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "849d2d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Morocco and Ethiopia'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_key[2][498:518]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e112f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_start = {}\n",
    "common_end = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23fe7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in common_start_keys:\n",
    "    multiplied_score = albert_pred[example_key][\"start\"][start] * xlnet_pred[example_key][\"start\"][start]\n",
    "    common_start[start] = multiplied_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4791d44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{481: 8.21418e-06,\n",
       " 493: 2.6791065e-08,\n",
       " 498: 0.9712962,\n",
       " 149: 2.2289498e-08,\n",
       " 510: 4.8901444e-07}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b458e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for end in common_end_keys:\n",
    "    multiplied_score = albert_pred[example_key][\"end\"][end] * xlnet_pred[example_key][\"end\"][end]\n",
    "    common_end[end] = multiplied_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "101f0141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{192: 3.9915645e-05,\n",
       " 164: 2.0033996e-05,\n",
       " 518: 0.98257,\n",
       " 522: 2.1991852e-06,\n",
       " 530: 3.778412e-08,\n",
       " 470: 1.643594e-08,\n",
       " 247: 0.00032905187,\n",
       " 505: 7.673721e-06,\n",
       " 509: 4.6295842e-08}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0e8d290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498 518\n"
     ]
    }
   ],
   "source": [
    "highest_start = max(common_start.items(), key=lambda x:x[1])[0]\n",
    "highest_end = max(common_end.items(), key=lambda x:x[1])[0]\n",
    "print(highest_start, highest_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e010b74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Morocco and Ethiopia'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_key[2][highest_start:highest_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b62100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ans = []\n",
    "for start in common_start.keys():\n",
    "    for end in common_end.keys():\n",
    "        if (end < start) or (end - start + 1) > max_answer_length:\n",
    "            continue\n",
    "        if start <= end:\n",
    "            valid_ans.append({\n",
    "                \"score\":common_start[start] + common_end[end],\n",
    "                \"text\":example_key[2][start:end]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "312b5a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.9538662, 'text': 'Morocco and Ethiopia'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(valid_ans, key=lambda x: x[\"score\"], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a64d3f2",
   "metadata": {},
   "source": [
    "## Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a010371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(model1_pred, model2_pred):\n",
    "    assert model1_pred.keys() == model2_pred.keys(), \"Predictions are not on the same dataset\"\n",
    "    final_predictions = {}\n",
    "    questions = model1_pred.keys()\n",
    "    for question in questions:\n",
    "        qid, actual_ans, context = question\n",
    "        common_start_keys = set(model1_pred[example_key][\"start\"]).intersection(model2_pred[example_key][\"start\"])\n",
    "        common_end_keys = set(model1_pred[example_key][\"end\"]).intersection(model2_pred[example_key][\"end\"])\n",
    "        \n",
    "        common_start = {}\n",
    "        common_end = {}\n",
    "        for start in common_start_keys:\n",
    "            multiplied_score = albert_pred[example_key][\"start\"][start] * xlnet_pred[example_key][\"start\"][start]\n",
    "            common_start[start] = multiplied_score\n",
    "        for end in common_end_keys:\n",
    "            multiplied_score = albert_pred[example_key][\"end\"][end] * xlnet_pred[example_key][\"end\"][end]\n",
    "            common_end[end] = multiplied_score\n",
    "#         highest_start = max(common_start.items(), key=lambda x:x[1])[0]\n",
    "#         highest_end = max(common_end.items(), key=lambda x:x[1])[0]\n",
    "#         highest_score_ans = context[highest_start:highest_end]\n",
    "#         final_predictions.update({actual_ans:highest_score_ans})\n",
    "\n",
    "        valid_ans = []\n",
    "        for start in common_start.keys():\n",
    "            for end in common_end.keys():\n",
    "                if (end < start) or (end - start + 1) > max_answer_length:\n",
    "                    continue\n",
    "                if start <= end:\n",
    "                    valid_ans.append({\n",
    "                        \"score\":common_start[start] + common_end[end],\n",
    "                        \"text\":context[start:end]\n",
    "                    })\n",
    "        final_pred = sorted(valid_ans, key=lambda x: x[\"score\"], reverse=True)[0][\"text\"]\n",
    "        final_predictions.update({actual_ans:final_pred})\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81f98419",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = get_answer(albert_pred, xlnet_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b9b0518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Morocco and Ethiopia': 'Morocco and Ethiopia',\n",
       " 'The European Court of Justice': 'of Justice is the hi',\n",
       " 'Waal': ', Nieuwe Maas (\"New ',\n",
       " 'the entertainment division': 'edesigned as part of',\n",
       " 'fifty thousand dollars': 'f work, Tesla fulfil',\n",
       " '1895': 'a mixture of acetyle',\n",
       " 'November 1979': 'ilitaries. By 1979, ',\n",
       " 'the Privy Council': ' justice. Cases invo',\n",
       " 'ideological struggle': 'ed HT as their key i',\n",
       " 'Peter Howell': '05, Murray Gold prov',\n",
       " 'Neutrophils and macrophages': 'ene of infection. Ma',\n",
       " 'newspaper editor': '',\n",
       " 'decline of organized labor': 'l pattern is clear; ',\n",
       " 'immunomodulators': 'one and vitamin D.',\n",
       " 'Brandon Marshall': 'ackles with 109, whi',\n",
       " 'February 1, 2016': '',\n",
       " 'unpaired electrons': 'net.[c]',\n",
       " 'compounds of oxygen with a high oxidative': 'rates, and dichromat',\n",
       " 'eight rows': 'rbances created by t',\n",
       " 'BBC Three': 'alekmania\" period (c',\n",
       " 'Santa Clara Marriott.': '',\n",
       " 'Jon Pertwee': 'ctorin\\' the Tardis\" ',\n",
       " 'the United Kingdom, Australia, Canada and the United States': ' Infinite Quest) was',\n",
       " 'criminalized behavior': ' for allegedly sendi',\n",
       " '1945': 'lished in 1945, was ',\n",
       " 'Onon River': 'm, constructed many ',\n",
       " 'Kings Canyon Avenue and Clovis Avenue': 'ed by William P. Bel',\n",
       " 'foundational constitutional questions affecting democracy and human rights': 'e case of an express',\n",
       " 'ONdigital': '31 October 2005, whi',\n",
       " '1964 and 1968': 'areholder of an ener',\n",
       " '‘combs’ – groups of cilia': 'ist of a mass of jel',\n",
       " '7.8%': 'ely occupied, arguab',\n",
       " 'Ed Lee': 'g to have to leave\".',\n",
       " 'as a scourge': ' our people were an ',\n",
       " 'pep rally': '',\n",
       " 'temperatures that are too cold in northern Europe for the survival of fleas': ' include the lack of',\n",
       " 'Harrods': 'he Talbot Hughes col',\n",
       " '720p high definition': 'se a primary feed AB',\n",
       " 'inequality in wealth and income': ' benefits do not tri',\n",
       " '1523': 'ace alone\" more full',\n",
       " 'Daewoo': 'eganza, Lanos and Ma',\n",
       " 'Guo Shoujing': '. The city of Beijin',\n",
       " 'since the 1960s': ' legal effect in the',\n",
       " 'it developed into a major part of the Internet backbone': \" to the nation's NSF\",\n",
       " 'an Eastern Bloc city': 'ldings, and churches',\n",
       " 'TEU articles 4 and 5': ' Committee\" is conve',\n",
       " 'Sun Life Stadium': '2013, the Florida le',\n",
       " 'Ghazan Khan': 'dani, the Mongols ki',\n",
       " 'independent': '[clarification neede',\n",
       " '$5 million in cash': 'uMont Television Net',\n",
       " 'oceanic': 'e Gulf Stream, such ',\n",
       " 'Demaryius Thomas': 'lement of the passin',\n",
       " 'vary': '',\n",
       " 'LGBT': 'posal that calls for',\n",
       " 'Rhijn': ' Dutch Rijn (formerl',\n",
       " 'Nafzger': 'd quality improvemen',\n",
       " 'Paul Revere': 'a church that dates ',\n",
       " 'hold a set speed': ', engines equipped o',\n",
       " 'Coronation Street': 'amme was scheduled a',\n",
       " 'Robert Maynard Hutchins': 'ity of Chicago and N',\n",
       " 'Pittsburgh Steelers': '',\n",
       " 'surface condensers': 'e the rejected heat ',\n",
       " 'a river crevice': \"his Khan's future ge\",\n",
       " 'difference in potential energy': 'on and amount of a f',\n",
       " 'shaping ideas about the free market': 'cs, the university w',\n",
       " 'ether': 'te or be split in an',\n",
       " 'demographics and economic ties': 'rnia is a major econ',\n",
       " 'British patrons': 'pendale, Pugin, Will',\n",
       " 'mucus': 't. In the lungs, cou',\n",
       " 'Freeview': 'rth.',\n",
       " '356 ± 47 tonnes': 'n with many more rem',\n",
       " 'a diatom (heterokontophyte) derived chloroplast': 'sts—practically a co',\n",
       " 'The Genghis Khan Mausoleum': 'm, constructed many ',\n",
       " '10th and 11th centuries': 'uld gradually merge ',\n",
       " 'Jonathan Stewart': '04 yards and seven t',\n",
       " 'San Jose State practice facility': '',\n",
       " 'Peyton Manning': '',\n",
       " 'public service': 'ms. However, ABC mad',\n",
       " 'Arizona Cardinals': ' They joined the Pat',\n",
       " 'increasingly expected to be compensated for their patient care skills': ' individual. The res',\n",
       " 'adaptive': ' form of either pass',\n",
       " 'New England Patriots': ' They joined the Pat',\n",
       " 'Marquis de la Jonquière': 'luding French-Canadi',\n",
       " 'Executive Vice President of Football Operations and General Manager': '',\n",
       " 'little': ' of income inequalit',\n",
       " 'ten to fifteen': ' chapters. Contribut',\n",
       " 'dioxygen': 'en gas constitutes 2',\n",
       " 'Manned Spacecraft Center': 'g the workability of',\n",
       " 'union government': 'on appears in the Co',\n",
       " 'January 27, 1967': 're erupted onto the ',\n",
       " 'EAT!': ' the regions profess',\n",
       " '$45,000': 'n $45,000 at several',\n",
       " 'emissions per person': 'lution created as th',\n",
       " 'unification': 'evelopment of quantu',\n",
       " 'Lenin': 'n would be abandoned',\n",
       " 'global': 'r countries and the ',\n",
       " 'WATCH ABC': 'WATCH\" brand used by',\n",
       " 'Abu al-Rayhan al-Biruni': 'Persian scholar Ibn ',\n",
       " 'residency registration': 'like renowned specia'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391a455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
