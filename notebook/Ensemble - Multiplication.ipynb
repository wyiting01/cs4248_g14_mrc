{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd30aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AlbertForQuestionAnswering, AlbertTokenizerFast, XLNetForQuestionAnswering, XLNetTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a37d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_dict = torch.load('../model/xlnet.pt',map_location=torch.device(\"cpu\"))\n",
    "albert_dict = torch.load('../model/albert.pt',map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de7f31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForQuestionAnswering were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['end_logits.LayerNorm.weight', 'start_logits.dense.weight', 'end_logits.LayerNorm.bias', 'answer_class.dense_0.weight', 'end_logits.dense_1.weight', 'answer_class.dense_1.weight', 'end_logits.dense_1.bias', 'answer_class.dense_0.bias', 'end_logits.dense_0.bias', 'start_logits.dense.bias', 'end_logits.dense_0.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating models\n",
    "\n",
    "# xlnet\n",
    "xlnet = XLNetForQuestionAnswering.from_pretrained('xlnet-base-cased')\n",
    "xlnet.load_state_dict(xlnet_dict[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "# albert\n",
    "albert = AlbertForQuestionAnswering.from_pretrained(\"albert-base-v2\")\n",
    "albert.load_state_dict(albert_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2acbde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(Dataset):\n",
    "\n",
    "    def __init__(self, input_path, tokenizer_checkpoint):\n",
    "        \"\"\"\n",
    "        input_path: path that contains all the files - contexts, questions, answers, answer spans and question ids\n",
    "        \"\"\"\n",
    "        print(f\"Reading in Dataset from {input_path}\")\n",
    "        \n",
    "        with open(input_path + \"/context\", encoding='utf-8') as f:\n",
    "            contexts = f.read().split(\"\\t\")\n",
    "        with open(input_path + \"/question\", encoding='utf-8') as f:\n",
    "            questions = f.read().split(\"\\t\")\n",
    "        with open(input_path + \"/answer\", encoding='utf-8') as f:\n",
    "            answers = f.read().split(\"\\t\")\n",
    "        with open(input_path + \"/answer_span\", encoding='utf-8') as f:\n",
    "            spans = f.read().split(\"\\t\")\n",
    "        with open(input_path + \"/question_id\", encoding='utf-8') as f:\n",
    "            qids = f.read().split(\"\\t\")\n",
    "\n",
    "        self.contexts = [ctx.strip() for ctx in contexts][:100]\n",
    "        self.questions = [qn.strip() for qn in questions][:100]\n",
    "        self.answers = [ans.strip() for ans in answers][:100]\n",
    "        self.spans = [span.strip().split() for span in spans][:100]\n",
    "        self.start_indices = [int(x[0]) for x in self.spans]\n",
    "        self.end_indices = [int(x[1]) for x in self.spans]\n",
    "        self.qids = [qid.strip() for qid in qids][:100]\n",
    "\n",
    "        # intialise XLNetTokenizerFast for input tokenization\n",
    "        if tokenizer_checkpoint == \"xlnet-base-cased\":\n",
    "          self.tokenizer = XLNetTokenizerFast.from_pretrained(\"xlnet-base-cased\")\n",
    "        elif tokenizer_checkpoint == \"albert-base-v2\":\n",
    "          self.tokenizer = AlbertTokenizerFast.from_pretrained(\"albert-base-v2\")\n",
    "        self.tokenizer.padding_side = \"right\"\n",
    "\n",
    "        # extract tokenization outputs\n",
    "        self.tokenizer_dict = self.tokenize()\n",
    "        self.sample_mapping, self.offset_mapping = self.preprocess()\n",
    "\n",
    "        self.input_ids = self.tokenizer_dict[\"input_ids\"]\n",
    "        self.token_type_ids = self.tokenizer_dict[\"token_type_ids\"]\n",
    "        self.attention_mask = self.tokenizer_dict[\"attention_mask\"]\n",
    "\n",
    "\n",
    "    def tokenize(self, max_length=384, doc_stride=128):\n",
    "        \"\"\"\n",
    "        inputs:\n",
    "        1. max_length: specifies the length of the tokenized text\n",
    "        2. doc_stride: defines the number of overlapping tokens\n",
    "\n",
    "        output:\n",
    "        1. tokenizer_dict, which contains\n",
    "        - input_ids: list of integer values representing the tokenized text; each integer corresponds to a specific token\n",
    "        - token_type_ids: to distinguish between question and context\n",
    "        - attention_mask: a binary mask that tells the model which tokens to mask/not mask\n",
    "        - sample_mapping: map from a feature to its corresponding example, since one question-context pair might give several features\n",
    "        - offset_mapping: maps each input id with the corresponding start and end characters in the original text\n",
    "\n",
    "        Tokenize examples (question-context pairs) with truncation and padding, but keep the overflows using a stride specified by `doc_stride`. \n",
    "        When the question-context input exceeds the `max_length`, it will contain more than one feature, and each of these features will have context\n",
    "        that overlaps a bit with the previous features, and the overlapping is determined by `doc_stride`. This is to ensure that although truncation\n",
    "        is performed, these overflows will ensure that no answer is missed as long as the answer span is shorter than the length of the overlap.\n",
    "        \"\"\"\n",
    "        print(\"Performing tokenization on dataset\")\n",
    "        tokenizer_dict = self.tokenizer(\n",
    "            self.questions,\n",
    "            self.contexts,\n",
    "            truncation=\"only_second\",\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            stride=doc_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "        return tokenizer_dict\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        This functions is to preprocess the outputs of the tokenizer dictionary.\n",
    "        Due to the possibility that an example has multiple features, this functions ensure that the start_positions and end_positions are mapped\n",
    "        correctly\n",
    "        \"\"\"\n",
    "        print(\"Preprocessing Dataset\")\n",
    "\n",
    "        sample_mapping = self.tokenizer_dict.pop(\"overflow_to_sample_mapping\")\n",
    "        offset_mapping = self.tokenizer_dict.pop(\"offset_mapping\")\n",
    "\n",
    "        self.tokenizer_dict[\"start_positions\"] = []\n",
    "        self.tokenizer_dict[\"end_positions\"] = []\n",
    "\n",
    "        for i, offsets in enumerate(offset_mapping):\n",
    "            input_ids = self.tokenizer_dict[\"input_ids\"][i]\n",
    "            cls_index = input_ids.index(self.tokenizer.cls_token_id)\n",
    "            sequence_ids = self.tokenizer_dict.sequence_ids(i)\n",
    "\n",
    "            sample_index = sample_mapping[i]\n",
    "            answer = self.answers[sample_index]\n",
    "            start_char = self.start_indices[sample_index]\n",
    "            end_char = self.end_indices[sample_index]\n",
    "\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # if answer is out of the span\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                self.tokenizer_dict[\"start_positions\"].append(cls_index)\n",
    "                self.tokenizer_dict[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                self.tokenizer_dict[\"start_positions\"].append(token_start_index - 1)\n",
    "\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                self.tokenizer_dict[\"end_positions\"].append(token_end_index + 1)\n",
    "        return sample_mapping, offset_mapping\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of features in the data\n",
    "        \"\"\"\n",
    "        return len(self.sample_mapping)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        og_index = self.sample_mapping[i]\n",
    "\n",
    "        item_dict = {\n",
    "            \"input_ids\": torch.tensor(self.input_ids[i]),\n",
    "            \"attention_mask\" : torch.tensor(self.attention_mask[i]),\n",
    "            \"start_positions\" : torch.tensor(self.tokenizer_dict[\"start_positions\"][i]),\n",
    "            \"end_positions\" : torch.tensor(self.tokenizer_dict[\"end_positions\"][i]),\n",
    "            \"og_indices\": og_index,\n",
    "            \"og_contexts\": self.contexts[og_index],\n",
    "            \"og_questions\": self.questions[og_index],\n",
    "            \"og_answers\": self.answers[og_index],\n",
    "            \"og_start_indices\": self.start_indices[og_index],\n",
    "            \"og_end_indices\": self.end_indices[og_index],\n",
    "            \"offset_mapping\": torch.tensor(self.offset_mapping[i]),\n",
    "            \"og_question_ids\": self.qids[og_index]\n",
    "\n",
    "        }\n",
    "        return item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5ff5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in Dataset from ../data/curated/test_data\n",
      "Performing tokenization on dataset\n",
      "Preprocessing Dataset\n",
      "Reading in Dataset from ../data/curated/test_data\n",
      "Performing tokenization on dataset\n",
      "Preprocessing Dataset\n"
     ]
    }
   ],
   "source": [
    "xlnet_data = SquadDataset(\"../data/curated/test_data\", \"xlnet-base-cased\")\n",
    "albert_data = SquadDataset(\"../data/curated/test_data\", \"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0d9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_albert(model, dataset, n_best_size=20, max_answer_length=30, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    test_dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    pred = {}\n",
    "\n",
    "    print(\"Making Predictions on Test Dataset\")\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            start = data[\"start_positions\"].to(device)\n",
    "            end = data[\"end_positions\"].to(device)\n",
    "\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            offset_mapping = data[\"offset_mapping\"]\n",
    "            context = data[\"og_contexts\"]\n",
    "            answer = data[\"og_answers\"]\n",
    "            question = data[\"og_questions\"]\n",
    "            qids = data[\"og_question_ids\"]\n",
    "\n",
    "            for i in range(len(input_ids)):\n",
    "\n",
    "                start_logits = F.softmax(output.start_logits[i], dim=0).cpu().detach().numpy()\n",
    "                end_logits = F.softmax(output.end_logits[i], dim=0).cpu().detach().numpy()\n",
    "                start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "\n",
    "                offsets = offset_mapping[i]\n",
    "                ctxt = context[i]\n",
    "                qid = qids[i]\n",
    "                ans = answer[i]\n",
    "\n",
    "                start_candidates = {}\n",
    "                end_candidates = {}\n",
    "\n",
    "                for start in start_indexes:\n",
    "                  logits = start_logits[start]\n",
    "                  start_char = offsets[start][0].item()\n",
    "                  if start_candidates.get(start_char) == None or start_candidates.get(start_char) < logits:\n",
    "                    start_candidates[start_char] = logits\n",
    "\n",
    "                for end in end_indexes:\n",
    "                  logits = end_logits[end]\n",
    "                  end_char = offsets[end][1].item()\n",
    "                  if end_candidates.get(end_char) == None or end_candidates.get(end_char) < logits:\n",
    "                    end_candidates[end_char] = logits\n",
    "\n",
    "                pred[(qid, ans, ctxt)] = {\"start\": start_candidates, \"end\": end_candidates}\n",
    "\n",
    "    return pred\n",
    "\n",
    "def test_xlnet(model, dataset, n_best_size=20, max_answer_length=30, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    test_dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    pred = {}\n",
    "\n",
    "    print(\"Making Predictions on Test Dataset\")\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            start = data[\"start_positions\"].to(device)\n",
    "            end = data[\"end_positions\"].to(device)\n",
    "\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            offset_mapping = data[\"offset_mapping\"]\n",
    "            context = data[\"og_contexts\"]\n",
    "            answer = data[\"og_answers\"]\n",
    "            question = data[\"og_questions\"]\n",
    "            qids = data[\"og_question_ids\"]\n",
    "\n",
    "            for i in range(len(input_ids)):\n",
    "                start_logits = output.start_top_log_probs[i].cpu().detach().numpy()\n",
    "                end_logits = output.end_top_log_probs[i].cpu().detach().numpy()\n",
    "                start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "                end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "\n",
    "                start_top_indexes = output.start_top_index[i]\n",
    "                end_top_indexes = output.end_top_index[i]\n",
    "\n",
    "                offsets = offset_mapping[i]\n",
    "                ctxt = context[i]\n",
    "                qid = qids[i]\n",
    "                ans = answer[i]\n",
    "\n",
    "                start_candidates = {}\n",
    "                end_candidates = {}\n",
    "                for start in start_indexes:\n",
    "                  logits = start_logits[start]\n",
    "                  start_index = start_top_indexes[start]\n",
    "                  start_char = offsets[start_index][0].item()\n",
    "                  if start_candidates.get(start_char) == None or start_candidates.get(start_char) < logits:\n",
    "                    start_candidates[start_char] = logits\n",
    "\n",
    "                for end in end_indexes:\n",
    "                  logits = end_logits[end]\n",
    "                  end_index = end_top_indexes[end]\n",
    "                  end_char = offsets[end_index][1].item()\n",
    "                  if end_candidates.get(end_char) == None or end_candidates.get(end_char) < logits:\n",
    "                    end_candidates[end_char] = logits\n",
    "\n",
    "                pred[(qid, ans, ctxt)] = {\"start\": start_candidates, \"end\": end_candidates}\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f88861",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_best_size = 20\n",
    "max_answer_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2aba1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Predictions on Test Dataset\n",
      "Making Predictions on Test Dataset\n"
     ]
    }
   ],
   "source": [
    "albert_pred = test_albert(albert, albert_data, n_best_size, max_answer_length=30, device='cpu')\n",
    "xlnet_pred = test_xlnet(xlnet, xlnet_data, n_best_size, max_answer_length=30, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51be6192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albert_pred.keys() == xlnet_pred.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69da3d",
   "metadata": {},
   "source": [
    "## Test on One Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_key = next(iter(albert_pred.keys()))\n",
    "example_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2574892",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(albert_pred[example_key][\"start\"])\n",
    "print(albert_pred[example_key][\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6027f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xlnet_pred[example_key][\"start\"])\n",
    "print(xlnet_pred[example_key][\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_start_keys = set(albert_pred[example_key][\"start\"]).intersection(xlnet_pred[example_key][\"start\"])\n",
    "common_end_keys = set(albert_pred[example_key][\"end\"]).intersection(xlnet_pred[example_key][\"end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(common_start_keys)\n",
    "print(common_end_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849d2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_key[2][498:518]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_start = {}\n",
    "common_end = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in common_start_keys:\n",
    "    multiplied_score = albert_pred[example_key][\"start\"][start] * xlnet_pred[example_key][\"start\"][start]\n",
    "    common_start[start] = multiplied_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4791d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for end in common_end_keys:\n",
    "    multiplied_score = albert_pred[example_key][\"end\"][end] * xlnet_pred[example_key][\"end\"][end]\n",
    "    common_end[end] = multiplied_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_start = max(common_start.items(), key=lambda x:x[1])[0]\n",
    "highest_end = max(common_end.items(), key=lambda x:x[1])[0]\n",
    "print(highest_start, highest_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e010b74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_key[2][highest_start:highest_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ans = []\n",
    "for start in common_start.keys():\n",
    "    for end in common_end.keys():\n",
    "        if (end < start) or (end - start + 1) > max_answer_length:\n",
    "            continue\n",
    "        if start <= end:\n",
    "            valid_ans.append({\n",
    "                \"score\":common_start[start] + common_end[end],\n",
    "                \"text\":example_key[2][start:end]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(valid_ans, key=lambda x: x[\"score\"], reverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a64d3f2",
   "metadata": {},
   "source": [
    "## Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a010371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(model1_pred, model2_pred):\n",
    "    assert model1_pred.keys() == model2_pred.keys(), \"Predictions are not on the same dataset\"\n",
    "    final_predictions = {}\n",
    "    questions = model1_pred.keys()\n",
    "    for question in questions:\n",
    "        qid, actual_ans, context = question\n",
    "        common_start_keys = set(model1_pred[question][\"start\"]).intersection(model2_pred[question][\"start\"])\n",
    "        common_end_keys = set(model1_pred[question][\"end\"]).intersection(model2_pred[question][\"end\"])\n",
    "        \n",
    "        common_start = {}\n",
    "        common_end = {}\n",
    "        for start in common_start_keys:\n",
    "            multiplied_score = albert_pred[question][\"start\"][start] * xlnet_pred[question][\"start\"][start]\n",
    "            common_start[start] = multiplied_score\n",
    "        for end in common_end_keys:\n",
    "            multiplied_score = albert_pred[question][\"end\"][end] * xlnet_pred[question][\"end\"][end]\n",
    "            common_end[end] = multiplied_score\n",
    "#         highest_start = max(common_start.items(), key=lambda x:x[1])[0]\n",
    "#         highest_end = max(common_end.items(), key=lambda x:x[1])[0]\n",
    "#         highest_score_ans = context[highest_start:highest_end]\n",
    "#         final_predictions.update({actual_ans:highest_score_ans})\n",
    "\n",
    "        valid_ans = []\n",
    "        for start in common_start.keys():\n",
    "            for end in common_end.keys():\n",
    "                if (end < start) or (end - start + 1) > max_answer_length:\n",
    "                    continue\n",
    "                if start <= end:\n",
    "                    valid_ans.append({\n",
    "                        \"score\":common_start[start] + common_end[end],\n",
    "                        \"text\":context[start:end]\n",
    "                    })\n",
    "        final_pred = sorted(valid_ans, key=lambda x: x[\"score\"], reverse=True)[0][\"text\"]\n",
    "        final_predictions.update({qid:final_pred})\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f98419",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = get_answer(albert_pred, xlnet_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b9b0518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5729281baf94a219006aa122': 'Morocco and Ethiopia',\n",
       " '57268bf9dd62a815002e890c': 'The European Court of Justice',\n",
       " '572ff7ab04bcaa1900d76f53': 'Boven Merwede',\n",
       " '57277cf6dd62a815002e9e78': 'entertainment division',\n",
       " '56e0d6367aa994140058e773': 'fifty thousand dollars',\n",
       " '571c9348dd7acb1400e4c116': '1895',\n",
       " '57265526708984140094c2c1': 'November 1979',\n",
       " '57287ddf3acd2414000dfa3f': 'Privy Council',\n",
       " '57302efe04bcaa1900d772f6': 'to change Muslim public opinion',\n",
       " '5728177f2ca10214002d9db0': 'Peter Howell',\n",
       " '5729081d3f37b31900477fab': 'Neutrophils and macrophages',\n",
       " '56e11afbcd28a01900c675c8': 'newspaper editor',\n",
       " '5729e4291d04691400779653': 'decline of organized labor',\n",
       " '5729f9953f37b3190047861f': 'immunomodulators',\n",
       " '56beb6533aeaaa14008c9290': 'Brandon Marshall',\n",
       " '56d9b4ebdc89441400fdb70c': 'February 1, 2016',\n",
       " '571cc3dedd7acb1400e4c148': 'unpaired electrons',\n",
       " '571a50df4faf5e1900b8a962': 'Combustion hazards',\n",
       " '572659ea5951b619008f7051': 'eight',\n",
       " '57282036ff5b5019007d9da0': 'BBC One channel',\n",
       " '56d70d240d65d21400198329': 'Santa Clara Marriott',\n",
       " '572819864b864d190016447e': 'Jon Pertwee',\n",
       " '5728274cff5b5019007d9e26': 'Australia, Canada and the United States',\n",
       " '5728284e3acd2414000df5cf': 'forbidden speech',\n",
       " '5725bbec271a42140099d0d4': 'The European Court of Justice',\n",
       " '5727c55bff5b5019007d94d0': '1945',\n",
       " '572732f8f1498d1400e8f476': 'Onon River',\n",
       " '5725db98ec44d21400f3d6c6': 'Kings Canyon Avenue and Clovis Avenue',\n",
       " '572699db5951b619008f779a': '',\n",
       " '57094b4f9928a814004714f6': 'ONdigital consortium',\n",
       " '57265e455951b619008f70bd': '1968',\n",
       " '5725c0f289a1e219009abdf3': 'combs’ – groups of cilia',\n",
       " '572678c0dd62a815002e863e': '7.8%',\n",
       " '56d7145c0d65d2140019834f': 'Ed Lee',\n",
       " '56f8989f9e9bad19000a01a5': 'a scourge sent to punish Christians by God',\n",
       " '56bf555e3aeaaa14008c95d4': 'pep rally',\n",
       " '57265285708984140094c25d': 'the spread of the Black Death was much faster',\n",
       " '5726e37ef1498d1400e8eedc': 'Harrods',\n",
       " '57275650708984140094dc5f': '720p high definition',\n",
       " '572a0e0e1d04691400779707': 'inequality in wealth and income',\n",
       " '56f87760aef23719006260cc': '1523',\n",
       " '573383d0d058e614000b5c37': 'Daewoo',\n",
       " '57287c142ca10214002da3d0': 'Guo Shoujing',\n",
       " '5726a14c708984140094cc51': 'since the 1960s',\n",
       " '572647e2dd62a815002e805e': 'public funding and private industry partnerships',\n",
       " '57332f81d058e614000b5778': 'an Eastern Bloc city',\n",
       " '572695285951b619008f774d': 'TEU articles 4 and 5',\n",
       " '56beb0f43aeaaa14008c921b': 'Sun Life Stadium',\n",
       " '572754cd5951b619008f8865': 'Ghazan Khan',\n",
       " '5727515f708984140094dc13': 'independent',\n",
       " '57273f9d708984140094db54': '$5 million',\n",
       " '57267383dd62a815002e8552': 'oceanic',\n",
       " '56bf38383aeaaa14008c956e': 'Demaryius Thomas',\n",
       " '56e7752337bdd419002c3fd7': 'vary',\n",
       " '5730b6bd2461fd1900a9cfd8': 'LGBT community',\n",
       " '572fe288a23a5019007fcadb': 'Rijn',\n",
       " '5725f39638643c19005acef7': 'Nafzger',\n",
       " '571097baa58dae1900cd6a98': 'Paul Revere',\n",
       " '57115dbe2419e314009555a9': 'hold a set speed',\n",
       " '572821ceff5b5019007d9db4': 'Coronation Street',\n",
       " '57284456ff5b5019007da05c': 'Robert Maynard Hutchins',\n",
       " '56d99f99dc89441400fdb628': 'Pittsburgh Steelers',\n",
       " '57115c7450c2381900b54a9d': 'surface condensers',\n",
       " '5726a5f65951b619008f7907': 'river crevice',\n",
       " '5737a7351c456719005744f4': 'difference in potential energy',\n",
       " '57286010ff5b5019007da1ca': 'shaping ideas about the free market',\n",
       " '56e120a1e3433e1400422c39': 'ether',\n",
       " '5705e26d75f01819005e76d7': 'San Diego, Santa Barbara, and Ventura',\n",
       " '5726d4a45951b619008f7f69': 'British patrons',\n",
       " '5728fb002ca10214002dab6d': 'mucus',\n",
       " '570963a5200fba1400367f36': 'Freeview',\n",
       " '5729f2646aef051400155133': '356 ± 47 tonnes',\n",
       " '572966ebaf94a219006aa392': 'diatom',\n",
       " '572732f8f1498d1400e8f477': 'Genghis Khan Mausoleum',\n",
       " '56ddde6b9a695914005b9629': '10th and 11th centuries',\n",
       " '56bf6b303aeaaa14008c960f': 'Jonathan Stewart',\n",
       " '56d70d240d65d21400198326': 'Stanford University',\n",
       " '56d7251d0d65d214001983cd': 'Peyton Manning',\n",
       " '57268739708984140094c8f1': 'public service',\n",
       " '56d98a59dc89441400fdb52b': 'Arizona Cardinals',\n",
       " '5726f868dd62a815002e9685': 'patient care skills',\n",
       " '5729f799af94a219006aa708': 'adaptive',\n",
       " '56bead5a3aeaaa14008c91eb': 'Patriots, Dallas Cowboys, and Pittsburgh Steelers',\n",
       " '5733e8ae4776f419006614a6': 'Marquis de la Jonquière',\n",
       " '56beb86b3aeaaa14008c92c0': 'General Manager',\n",
       " '5729e38daf94a219006aa6a0': 'little',\n",
       " '57293d6d1d046914007791b8': 'ten to fifteen',\n",
       " '571c3a685efbb31900334db6': 'dioxygen',\n",
       " '5725c604271a42140099d187': 'Manned Spacecraft Center',\n",
       " '57274beff1498d1400e8f5e7': 'the union government',\n",
       " '5725dc1638643c19005ace02': 'January 27, 1967',\n",
       " '57268109f1498d1400e8e1fd': 'NewcastleGateshead',\n",
       " '57274712708984140094dbad': '$45,000',\n",
       " '572a1f086aef0514001552c1': 'environmental degradation',\n",
       " '5737821cc3c5551400e51f1b': 'unification models',\n",
       " '5730b4282461fd1900a9cfc6': 'Mao Zedong',\n",
       " '5729f1283f37b319004785d7': 'global to a domestic scale',\n",
       " '57277af2708984140094dec3': 'WATCH ABC',\n",
       " '572683f95951b619008f7526': 'Abu al-Rayhan al-Biruni',\n",
       " '57337f6ad058e614000b5bcf': 'residency registration'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391a455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
