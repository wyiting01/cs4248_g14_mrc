{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Optuna to find best weights to do ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import collections\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../../ensemble/roberta_val.json')\n",
    "roberta_pred = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('../../ensemble/xlnet_val.json')\n",
    "xlnet_pred = json.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "  def remove_articles(text):\n",
    "    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "    return re.sub(regex, ' ', text)\n",
    "  def white_space_fix(text):\n",
    "    return ' '.join(text.split())\n",
    "  def remove_punc(text):\n",
    "    exclude = set(string.punctuation)\n",
    "    return ''.join(ch for ch in text if ch not in exclude)\n",
    "  def lower(text):\n",
    "    return text.lower()\n",
    "  return white_space_fix(remove_articles(remove_punc(lower(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(s):\n",
    "  if not s: return []\n",
    "  return normalize_answer(s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(a_gold, a_pred):\n",
    "  gold_toks = get_tokens(a_gold)\n",
    "  pred_toks = get_tokens(a_pred)\n",
    "  common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "  num_same = sum(common.values())\n",
    "  if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "    return int(gold_toks == pred_toks)\n",
    "  if num_same == 0:\n",
    "    return 0\n",
    "  precision = 1.0 * num_same / len(pred_toks)\n",
    "  recall = 1.0 * num_same / len(gold_toks)\n",
    "  f1 = (2 * precision * recall) / (precision + recall)\n",
    "  return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting_score(xlnet, roberta, w1, w2):\n",
    "    wdict  = {}\n",
    "    for qns_id in xlnet.keys():\n",
    "        xlnet_ans_start = xlnet.get(qns_id).get('start')\n",
    "        roberta_ans_start = roberta.get(qns_id).get('start')\n",
    "        ans = roberta.get(qns_id).get('answers')\n",
    "        ctxt = roberta.get(qns_id).get('context')\n",
    "\n",
    "        weighted_ans_start = {}\n",
    "\n",
    "        for key, val in roberta_ans_start.items(): # start w xlnet as it has less candidates\n",
    "            #roberta_score = roberta_ans_start.get(key)\n",
    "            xlnet_score = xlnet_ans_start.get(key)\n",
    "            if xlnet_score == None:\n",
    "                weighted_ans_start[key] = w2*float(val)\n",
    "            else:\n",
    "                 weighted_ans_start[key] = w1*float(xlnet_score) + w2*float(val)\n",
    "\n",
    "        xlnet_ans_end = xlnet.get(qns_id).get('end')\n",
    "        roberta_ans_end = roberta.get(qns_id).get('end')\n",
    "        \n",
    "        weighted_ans_end = {}\n",
    "\n",
    "        for key, val in roberta_ans_end.items(): # start w xlnet as it has less candidates\n",
    "            #roberta_score = roberta_ans_end.get(key)\n",
    "            xlnet_score = xlnet_ans_end.get(key)\n",
    "            if xlnet_score == None:\n",
    "                weighted_ans_end[key] = w2*float(val)\n",
    "            else:\n",
    "                weighted_ans_end[key] = w1*float(xlnet_score) + w2*float(val)\n",
    "        wdict[qns_id] = {\"start\": weighted_ans_start, \"end\": weighted_ans_end, \"context\": ctxt, \"answer\": ans}\n",
    "    return wdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(score_dict, max_answer_length=100):\n",
    "    pred = {}\n",
    "    for qns in score_dict.keys():\n",
    "        ans = score_dict.get(qns).get('answer')\n",
    "        ctxt = score_dict.get(qns).get('context')\n",
    "        #print(ctxt)\n",
    "        valid_answer = {}\n",
    "        start_indexes = score_dict.get(qns)[\"start\"]\n",
    "        end_indexes = score_dict.get(qns)[\"end\"]\n",
    "        for start, s_score in start_indexes.items():\n",
    "            for end, e_score in end_indexes.items():\n",
    "                start = int(start)\n",
    "                end = int(end)\n",
    "                if end < start or end - start + 1 > max_answer_length:\n",
    "                    continue\n",
    "                if start <= end:\n",
    "                    pred_answer = ctxt[start:end]\n",
    "                    pred_score = s_score + e_score\n",
    "                    if valid_answer.get(pred_answer) == None or float(valid_answer.get(pred_answer)) < pred_score:\n",
    "                        valid_answer.update(\n",
    "                                {pred_answer : pred_score}\n",
    "                            )\n",
    "\n",
    "        valid_answer = dict(sorted(valid_answer.items(), key=lambda x: x[1], reverse=True))\n",
    "        #print(valid_answer)\n",
    "        if len(valid_answer) == 0:\n",
    "            print(qns, ans, valid_answer)\n",
    "            pred[qns] = (\" \", ans)\n",
    "            \n",
    "        else:\n",
    "            pred[qns] = (next(iter(valid_answer)), ans)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(final):\n",
    "  score = []\n",
    "  for val in final.values():\n",
    "    pred_ans = val[0]\n",
    "    gold_ans = val[1]\n",
    "    score.append(compute_f1(gold_ans, pred_ans))\n",
    "  #print(score)\n",
    "  return sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(w1=0.5, w2=0.5):\n",
    "\n",
    "    final_score = weighting_score(xlnet_pred, roberta_pred, w1, w2)\n",
    "    test_output = post_processing(final_score)\n",
    "    exact_score = evaluate(test_output)\n",
    "    \n",
    "    return exact_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "  STEP_SIZE = 0.01\n",
    "\n",
    "  weights = []\n",
    "  upper_limit = 1\n",
    "\n",
    "  w_roberta = trial.suggest_float(\"w_roberta\", 0, upper_limit, step=STEP_SIZE)\n",
    "  weights.append(w_roberta)\n",
    "\n",
    "  upper_limit -= sum(weights)\n",
    "  upper_limit = upper_limit\n",
    "\n",
    "  w_xlnet = 1-w_roberta\n",
    "  weights.append(w_xlnet)\n",
    "\n",
    "  weights_sum = sum(weights)\n",
    "  if weights_sum != 1:\n",
    "    raise Exception(f\"Weights sum must be equal to 1. Instead {weights_sum} was encountered!\")\n",
    "\n",
    "  #w2 = weights[0]\n",
    "  #w1 = weights[1]\n",
    "  metric = main(w_xlnet, w_roberta)\n",
    "  return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w_roberta': 0.61}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_roberta = study.best_params[\"w_roberta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_xlnet = 1-w_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39 0.61\n"
     ]
    }
   ],
   "source": [
    "print(w_xlnet, w_roberta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
